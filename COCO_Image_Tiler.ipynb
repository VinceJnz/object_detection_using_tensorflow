{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d89bf8",
   "metadata": {},
   "source": [
    "# COCO Image Tiler\n",
    "\n",
    "Tile larger COCO annotated images into smaller COCO annotated images\n",
    "\n",
    "This involves cutting up the images and fixing the COCO annotations so that they align with the new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4472c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current OS: nt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "print(f\"Current OS: {os.name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc65f0b",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0c005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image from a TF Record with its bounding boxes and labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plt_image_with_labels(image, annotations, categories):\n",
    "    ## Display the image, with bboxes and labels\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    height = annotations[\"image/height\"]\n",
    "    width = annotations[\"image/width\"]\n",
    "    # Create Rectangle patches, i.e. bbox add rectangles to the image\n",
    "    for j in range(len(annotations['image/object/class/label'])):\n",
    "        x1 = annotations[\"image/object/bbox/xmin\"][j] * width\n",
    "        y1 = annotations[\"image/object/bbox/ymin\"][j] * height\n",
    "        x2 = annotations[\"image/object/bbox/xmax\"][j] * width - x1\n",
    "        y2 = annotations[\"image/object/bbox/ymax\"][j] * height - y1\n",
    "        \n",
    "        category_num = annotations[\"image/object/class/label\"][j]-1\n",
    "        label = categories[category_num][\"name\"]\n",
    "        rect = patches.Rectangle((x1, y1), x2, y2, linewidth=1, edgecolor='red', facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1,y1, label, horizontalalignment='left', fontsize=8, color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6567ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image from a TF Record with its bounding boxes and labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plt_image_with_labels2(image, annotations, categories):\n",
    "    ## Display the image, with bboxes and labels\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    height = annotations['height']\n",
    "    width = annotations['width']\n",
    "    # Create Rectangle patches, i.e. bbox add rectangles to the image\n",
    "    for row in annotations['annotations']:\n",
    "        x1, y1, x2, y2 = row['bbox']\n",
    "        \n",
    "        category_num = row['category_id']-1\n",
    "        label = categories[category_num][\"name\"]\n",
    "        rect = patches.Rectangle((x1, y1), x2, y2, linewidth=1, edgecolor='red', facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1,y1, label, horizontalalignment='left', fontsize=8, color='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64084e46",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a862214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of folder paths to be created (if needed) and used later\n",
    "paths = {\n",
    "    #'IMAGE_SOURCE_PATH':os.path.join('images'),\n",
    "    'IMAGE_SOURCE_PATH':os.path.join('E:', os.sep,'Users','Vince','Datasets','NZRC','Gordon','CycloneGitaRawImagery','ML4DR_20210910_01'),\n",
    "    \n",
    "    # bounding box annotation\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d23787",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join('E:', os.sep ,'Users', 'Vince', 'Datasets', 'NZRC', 'Gordon', 'CycloneGitaRawImagery')\n",
    "tfrecords_dir = os.path.join(root_dir, \"ML4DR_20210910_01/tfrecords/val2017\")\n",
    "images_dir = os.path.join(root_dir, \"ML4DR_20210910_01\")\n",
    "annotations_dir = os.path.join(root_dir, \"ML4DR_20210910_01\")\n",
    "annotation_file = os.path.join(annotations_dir, \"ML4DR_20210910_01_coco.json\")\n",
    "paths['IMAGE_PATH'] = images_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88eebb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load COCO file information\n",
    "\n",
    "import json\n",
    "\n",
    "#Load image refs from COCO file\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    coco_images = json.load(f)[\"images\"]\n",
    "    \n",
    "#Load annotations from COCO file\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    coco_annotations = json.load(f)[\"annotations\"]\n",
    "    \n",
    "#Load categories from COCO file\n",
    "with open(annotation_file, \"r\") as f:\n",
    "    coco_categories = json.load(f)[\"categories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b55f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange COCO file info into a form that can be used to create the TF Record file\n",
    "# this requires the annotation info for each image be associated to the image info\n",
    "# and it requires a category dictionary to convert from category_id to category_text\n",
    "\n",
    "#Work through coco-images\n",
    "# Extract the image attributes\n",
    "# For each image get a list of annotations\n",
    "# Add the annotations list to the image\n",
    "\n",
    "imageInfoList = []\n",
    "for image_info in coco_images:\n",
    "    annotationsList = []\n",
    "    for annotation in coco_annotations:\n",
    "        if image_info['id'] == annotation['image_id']:\n",
    "            annotationsList.append(annotation)\n",
    "    if len(annotationsList)>0:\n",
    "        image = image_info\n",
    "        image['annotations'] = annotationsList\n",
    "        imageInfoList.append(image)\n",
    "        \n",
    "categories = {}\n",
    "labels = []\n",
    "for cat in coco_categories:\n",
    "    labels.append({'name':cat['name'], 'id':cat['id']})\n",
    "    categories[cat['id']] = cat['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7f0c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this for????\n",
    "#imageInfo = imageInfoList[0]\n",
    "#tf_example = scan_image_info(imageInfo, paths['IMAGE_SOURCE_PATH'], image_size)\n",
    "#print('type(tf_example) =',type(tf_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa45c296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(imageInfoList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9d21178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Vince\\Datasets\\NZRC\\Gordon\\CycloneGitaRawImagery\\ML4DR_20210910_01 Day_1_Images_Flight_1_DSC09232_geotag.JPG\n",
      "type(encoded_jpg) = <class 'bytes'>\n",
      "type(encoded_jpg_io) = <class '_io.BytesIO'>\n",
      "type(image) = <class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "imageInfo:\n"
     ]
    }
   ],
   "source": [
    "# fetch the imageInfo and the image\n",
    "\n",
    "imageInfo = imageInfoList[2]\n",
    "image_path = paths['IMAGE_SOURCE_PATH']\n",
    "\n",
    "with tf.io.gfile.GFile(os.path.join(image_path, '{}'.format(imageInfo['file_name'])), 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "image = Image.open(encoded_jpg_io)\n",
    "\n",
    "print(image_path, imageInfo['file_name'])\n",
    "print('type(encoded_jpg) =', type(encoded_jpg))\n",
    "print('type(encoded_jpg_io) =', type(encoded_jpg_io))\n",
    "print('type(image) =', type(image))\n",
    "print('imageInfo:')\n",
    "#print(imageInfo)\n",
    "\n",
    "#plt_image_with_labels2(image, imageInfo, coco_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4bd7cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bboxes that are within the crop_box\n",
    "# and adjust their coordinates to fit within the cropped image\n",
    "\n",
    "def get_bboxes(crop_box, imageInfo):\n",
    "    adj_bboxes = []\n",
    "    for a in imageInfo['annotations']:\n",
    "        bbox_x1, bbox_y1, bbox_x2, bbox_y2 = a['bbox']\n",
    "        bbox_x2 += bbox_x1\n",
    "        bbox_y2 += bbox_y1\n",
    "        crop_x1, crop_y1, crop_x2, crop_y2 = crop_box\n",
    "\n",
    "        # If top-left bbox corner is inside the crop box\n",
    "        if crop_x1 < bbox_x1 and crop_y1 < bbox_y1:\n",
    "            # If bottom-right bbox corner is inside the crop box\n",
    "            if bbox_x2 < crop_x2 and bbox_y2 < crop_y2:\n",
    "                adj_bboxes.append([a['bbox'][0]-crop_x1, a['bbox'][1]-crop_y1, a['bbox'][2], a['bbox'][3]])\n",
    "\n",
    "    return adj_bboxes\n",
    "    #return imageInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dd6589db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size = (6000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# Extract image tiles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "crop_size = (1000, 1000)\n",
    "crop_overlap = 200\n",
    "image_size = image.size\n",
    "print('image_size =', image_size)\n",
    "\n",
    "img_count = 0\n",
    "new_imageInfo = imageInfo\n",
    "new_imageInfoList = []\n",
    "for x in range(0, image.size[0]-crop_overlap, crop_size[0]-crop_overlap):\n",
    "    if x >= image_size[0]-crop_size[0]:\n",
    "        x = image_size[0]-crop_size[0]\n",
    "    for y in range(0, image.size[1]-crop_overlap, crop_size[1]-crop_overlap):\n",
    "        img_count += 1\n",
    "        if y >= image_size[1]-crop_size[1]:\n",
    "            y = image_size[1]-crop_size[1]\n",
    "        crop_box = (x, y, x+crop_size[0], y+crop_size[1])\n",
    "\n",
    "        bboxes = get_bboxes(crop_box, imageInfo)\n",
    "        #fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        #ax.imshow(image.crop(crop_box))\n",
    "        #plt.show()\n",
    "\n",
    "        #plt_image_with_labels(image_np, item, coco_categories)\n",
    "        new_imageInfo['id'] = imageInfo['id'] + img_count\n",
    "        new_imageInfo['width'], new_imageInfo['height'] = crop_size\n",
    "        #Need a function to insert the img_count into the file name\n",
    "        # new_imageInfo['file_name'] = imageInfo['file_name'] + '_' + img_count\n",
    "        # new_imageInfo['flickr_url'] = imageInfo['flickr_url']\n",
    "        # new_imageInfo['coco_url'] = imageInfo['coco_url']\n",
    "\n",
    "        new_imageInfoList.append(new_imageInfo)\n",
    "        \n",
    "#return new_imageInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cbeb01ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imageInfo = imageInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19155d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_imageInfo['id'] = NewImageInfo['id'] * img_count\n",
    "new_imageInfo['width'] = \n",
    "new_imageInfo['height'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e038d94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 24,\n",
       " 'width': 6000,\n",
       " 'height': 4000,\n",
       " 'file_name': 'Day_1_Images_Flight_1_DSC09232_geotag.JPG',\n",
       " 'license': 0,\n",
       " 'flickr_url': './Day_1_Images_Flight_1_DSC09232_geotag.JPG',\n",
       " 'coco_url': './Day_1_Images_Flight_1_DSC09232_geotag.JPG',\n",
       " 'date_captured': '',\n",
       " 'annotations': [{'segmentation': [[3631,\n",
       "     308,\n",
       "     3779,\n",
       "     308,\n",
       "     3779,\n",
       "     446,\n",
       "     3631,\n",
       "     446]],\n",
       "   'area': 20424,\n",
       "   'bbox': [3631, 308, 148, 138],\n",
       "   'iscrowd': 0,\n",
       "   'id': 3,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[3788, 529, 3896, 529, 3896, 638, 3788, 638]],\n",
       "   'area': 11772,\n",
       "   'bbox': [3788, 529, 108, 109],\n",
       "   'iscrowd': 0,\n",
       "   'id': 4,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[3883, 437, 4100, 437, 4100, 655, 3883, 655]],\n",
       "   'area': 47306,\n",
       "   'bbox': [3883, 437, 217, 218],\n",
       "   'iscrowd': 0,\n",
       "   'id': 5,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4006, 890, 4228, 890, 4228, 1093, 4006, 1093]],\n",
       "   'area': 45066,\n",
       "   'bbox': [4006, 890, 222, 203],\n",
       "   'iscrowd': 0,\n",
       "   'id': 6,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4411, 664, 4622, 664, 4622, 893, 4411, 893]],\n",
       "   'area': 48319,\n",
       "   'bbox': [4411, 664, 211, 229],\n",
       "   'iscrowd': 0,\n",
       "   'id': 7,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4400, 892, 4618, 892, 4618, 1106, 4400, 1106]],\n",
       "   'area': 46652,\n",
       "   'bbox': [4400, 892, 218, 214],\n",
       "   'iscrowd': 0,\n",
       "   'id': 8,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4671, 475, 4974, 475, 4974, 798, 4671, 798]],\n",
       "   'area': 97869,\n",
       "   'bbox': [4671, 475, 303, 323],\n",
       "   'iscrowd': 0,\n",
       "   'id': 9,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4731, 815, 4948, 815, 4948, 1027, 4731, 1027]],\n",
       "   'area': 46004,\n",
       "   'bbox': [4731, 815, 217, 212],\n",
       "   'iscrowd': 0,\n",
       "   'id': 10,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[5122, 965, 5356, 965, 5356, 1215, 5122, 1215]],\n",
       "   'area': 58500,\n",
       "   'bbox': [5122, 965, 234, 250],\n",
       "   'iscrowd': 0,\n",
       "   'id': 11,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4640, 1099, 4867, 1099, 4867, 1329, 4640, 1329]],\n",
       "   'area': 52210,\n",
       "   'bbox': [4640, 1099, 227, 230],\n",
       "   'iscrowd': 0,\n",
       "   'id': 12,\n",
       "   'image_id': 24,\n",
       "   'category_id': 1},\n",
       "  {'segmentation': [[4986, 752, 5111, 752, 5111, 882, 4986, 882]],\n",
       "   'area': 16250,\n",
       "   'bbox': [4986, 752, 125, 130],\n",
       "   'iscrowd': 0,\n",
       "   'id': 13,\n",
       "   'image_id': 24,\n",
       "   'category_id': 2}]}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageInfo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
